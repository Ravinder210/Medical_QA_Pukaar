{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "691bb9c8-d2ff-4421-bcef-0675ee5740ea",
    "_uuid": "d8ee4a6b-9afd-4eec-af2f-e44a464f525f",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-04T21:33:41.870755Z",
     "iopub.status.busy": "2025-08-04T21:33:41.870028Z",
     "iopub.status.idle": "2025-08-04T21:33:41.875087Z",
     "shell.execute_reply": "2025-08-04T21:33:41.874408Z",
     "shell.execute_reply.started": "2025-08-04T21:33:41.870729Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"ncbi/MedCPT-Cross-Encoder\")\n",
    "rerank_model = AutoModelForSequenceClassification.from_pretrained(\"ncbi/MedCPT-Cross-Encoder\").to(device)\n",
    "\n",
    "def rerank_with_medcpt(query, passages):\n",
    "    inputs = tokenizer(\n",
    "        [f\"[Q] {query} [D] {p}\" for p in passages],\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        return_tensors=\"pt\"\n",
    "    ).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        logits = rerank_model(**inputs).logits.squeeze()\n",
    "        scores = logits.cpu().numpy().tolist()\n",
    "\n",
    "    return scores\n",
    "\n",
    "# Step 1: Rerank\n",
    "scores = rerank_with_medcpt(user_query, retrieved_texts)\n",
    "\n",
    "# Step 2: Sort by descending score\n",
    "ranked_results = sorted(\n",
    "    zip(retrieved_texts, retrieved_metas, scores),\n",
    "    key=lambda x: x[2],\n",
    "    reverse=True\n",
    ")\n",
    "\n",
    "# Step 3: Show top results\n",
    "for i, (text, meta, score) in enumerate(ranked_results[:]):\n",
    "    print(f\"\\nðŸ”¹ Reranked #{i+1} â€” Score: {score:.4f}\")\n",
    "    print(\"ðŸ“„ Metadata:\", meta)\n",
    "    print(\"ðŸ“œ Content Preview:\", text[:300], \"...\")\n",
    "\n",
    "# How many top reranked chunks to include?\n",
    "top_n = 5\n",
    "\n",
    "# System prompt\n",
    "system_prompt = (\n",
    "    \"You are a helpful clinical assistant. Use only the provided context to answer.\\n\"\n",
    "    \"Always cite the source and page number from the metadata.\"\n",
    ")\n",
    "\n",
    "# Build formatted context\n",
    "context_blocks = []\n",
    "for i, (text, meta, score) in enumerate(ranked_results[:top_n]):\n",
    "    context = f\"---\\nSource: {meta['source']}, Page: {meta['page']}, Section: {meta.get('section', '')}\\n{text.strip()}\"\n",
    "    context_blocks.append(context)\n",
    "\n",
    "# Combine everything\n",
    "final_prompt = f\"{system_prompt}\\n\\nUser Query:\\n{user_query}\\n\\nContext:\\n\" + \"\\n\\n\".join(context_blocks)\n",
    "\n",
    "print(\"ðŸ§¾ Final Prompt for LLM:\\n\")\n",
    "print(final_prompt)  # truncate preview if too long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "ec600fff-77d6-4d61-a03b-19f910a29778",
    "_uuid": "d4d1efcc-e45b-48c9-aa46-b68ff759a656",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-06T17:21:57.895097Z",
     "iopub.status.busy": "2025-08-06T17:21:57.894424Z",
     "iopub.status.idle": "2025-08-06T17:22:01.512951Z",
     "shell.execute_reply": "2025-08-06T17:22:01.512157Z",
     "shell.execute_reply.started": "2025-08-06T17:21:57.895070Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install -q sentence-transformers faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "5268d660-77fd-4290-ab42-03229693e150",
    "_uuid": "ce9f0ba3-9ca5-489f-b803-5d9bc9e85c8a",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-06T17:22:01.514268Z",
     "iopub.status.busy": "2025-08-06T17:22:01.514029Z",
     "iopub.status.idle": "2025-08-06T17:22:01.732943Z",
     "shell.execute_reply": "2025-08-06T17:22:01.732259Z",
     "shell.execute_reply.started": "2025-08-06T17:22:01.514242Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Aug  6 17:22:01 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 560.35.03              Driver Version: 560.35.03      CUDA Version: 12.6     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   46C    P8             11W /   70W |       1MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "|   1  Tesla T4                       Off |   00000000:00:05.0 Off |                    0 |\n",
      "| N/A   46C    P8             11W /   70W |       1MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4fbfc43c-c535-4ab1-9efb-cdb281f54dac",
    "_uuid": "a50601d5-b979-4fb3-bde4-54d45e2e2537",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-06T17:22:01.733888Z",
     "iopub.status.busy": "2025-08-06T17:22:01.733708Z",
     "iopub.status.idle": "2025-08-06T17:22:02.313093Z",
     "shell.execute_reply": "2025-08-06T17:22:02.312580Z",
     "shell.execute_reply.started": "2025-08-06T17:22:01.733868Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login(token=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "1011cdeb-4a3c-4930-98e1-9f0e126a679b",
    "_uuid": "4e27b9ad-9d33-4264-b050-22c09b558d41",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-06T17:22:02.313843Z",
     "iopub.status.busy": "2025-08-06T17:22:02.313675Z",
     "iopub.status.idle": "2025-08-06T17:22:41.994749Z",
     "shell.execute_reply": "2025-08-06T17:22:41.993944Z",
     "shell.execute_reply.started": "2025-08-06T17:22:02.313829Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-06 17:22:16.934738: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1754500937.183247      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1754500937.263850      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a2b657c32f344a7bfffcf3918fac466",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/229 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5a67e31eade460995eabaf596f92932",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/123 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a8b5780b1ad4c659b3e4435da9fd6fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4956de145f64cc5b3b500da800fe81e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b10b8af1337245c1a98c34fa449cb845",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/667 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57aeebbb16a0432c8717b18d6124e80d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5db50aaa5b04d05808dd2ef86ed5eed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b95492269f984f90b470c64f236ee6c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c8afdb301984c70900f06df33d02a7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09b3389ab4bb4e49bf3fc824023ac1c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/74.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f76a51ec45741049d069736df505c32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0545690d64c45c7bb6f2a2eef93eced",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer(\"NeuML/pubmedbert-base-embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "587140ba-6293-40bb-8622-ae456b47b00b",
    "_uuid": "ce9f2da4-d643-4853-a3d7-0a01cc710bab",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-06T17:22:42.000088Z",
     "iopub.status.busy": "2025-08-06T17:22:41.999855Z",
     "iopub.status.idle": "2025-08-06T17:22:42.036878Z",
     "shell.execute_reply": "2025-08-06T17:22:42.036342Z",
     "shell.execute_reply.started": "2025-08-06T17:22:42.000070Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "texts = []\n",
    "metadatas = []\n",
    "\n",
    "with open(\"/kaggle/input/chunks/page_chunks_Pocket_book_of_hospital_care.jsonl\", \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        obj = json.loads(line)\n",
    "        texts.append(obj[\"content\"])\n",
    "        metadatas.append(obj[\"metadata\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "8f5325ad-36e9-4b9d-b868-74e7b76b21d0",
    "_uuid": "c3c6acef-67e3-4720-89c9-c0981b429c6f",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-06T17:22:42.037644Z",
     "iopub.status.busy": "2025-08-06T17:22:42.037479Z",
     "iopub.status.idle": "2025-08-06T17:22:54.467452Z",
     "shell.execute_reply": "2025-08-06T17:22:54.466867Z",
     "shell.execute_reply.started": "2025-08-06T17:22:42.037630Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11126a6a10b94caa8f05f563fed1e71a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "embeddings = model.encode(texts, convert_to_numpy=True, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "ecf6578b-e851-4a26-8253-5aab20c56153",
    "_uuid": "d77d11ae-0f12-46f4-ab5a-d604afa0e5bb",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-06T17:22:54.468895Z",
     "iopub.status.busy": "2025-08-06T17:22:54.468585Z",
     "iopub.status.idle": "2025-08-06T17:22:54.504168Z",
     "shell.execute_reply": "2025-08-06T17:22:54.503416Z",
     "shell.execute_reply.started": "2025-08-06T17:22:54.468857Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… FAISS index has 438 vectors.\n"
     ]
    }
   ],
   "source": [
    "import faiss\n",
    "\n",
    "dimension = embeddings.shape[1]\n",
    "index = faiss.IndexFlatL2(dimension)\n",
    "index.add(embeddings)\n",
    "\n",
    "print(\"âœ… FAISS index has\", index.ntotal, \"vectors.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T17:22:54.505429Z",
     "iopub.status.busy": "2025-08-06T17:22:54.505147Z",
     "iopub.status.idle": "2025-08-06T17:22:54.512986Z",
     "shell.execute_reply": "2025-08-06T17:22:54.512409Z",
     "shell.execute_reply.started": "2025-08-06T17:22:54.505407Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import faiss\n",
    "\n",
    "# Save FAISS index\n",
    "faiss.write_index(index, \"faiss_index.index\")\n",
    "\n",
    "# Save texts and metadata (must align with index)\n",
    "with open(\"texts.pkl\", \"wb\") as f:\n",
    "    pickle.dump(texts, f)\n",
    "\n",
    "with open(\"metadatas.pkl\", \"wb\") as f:\n",
    "    pickle.dump(metadatas, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "d1bfb333-a003-410d-951f-1edc41a80016",
    "_kg_hide-output": true,
    "_uuid": "fe8a1ec4-8017-4fea-846c-c47cbac56511",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-06T17:22:54.514346Z",
     "iopub.status.busy": "2025-08-06T17:22:54.513820Z",
     "iopub.status.idle": "2025-08-06T17:22:54.554108Z",
     "shell.execute_reply": "2025-08-06T17:22:54.553589Z",
     "shell.execute_reply.started": "2025-08-06T17:22:54.514322Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66e2cf8f7a4a45b5a4dcafe118fbaef2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Result #1\n",
      "ðŸ“„ Metadata: {'source': 'POCKET BOOK OF Hospital care', 'page': 107, 'section': 'SEVERE PNEUMONIA'}\n",
      "ðŸ“œ Content Preview: SEVERE PNEUMONIA\n",
      "\n",
      "SEVERE PNEUMONIA\n",
      "\n",
      "## Supportive care\n",
      "\n",
      "* Remove by gentle suction any thick secretions at the entrance to the nasal passages or throat, which the child cannot clear.\n",
      "* If the child has fever (â‰¥ 39 Â°C or â‰¥ 102.2 Â°F) which appears to be causing distress, give paracetamol.\n",
      "* If wheeze  ...\n",
      "\n",
      "ðŸ”¹ Result #2\n",
      "ðŸ“„ Metadata: {'source': 'POCKET BOOK OF Hospital care', 'page': 79, 'section': 'MENINGITIS\\n\\n* For newborns with any signs of serious bacterial infection or sepsis, give ampicillin (or penicillin) and gentamicin as first-line antibiotic treatment (for dosages see pp. 69â€“72)\\n* If at greater risk of staphylococcus infection (extensive skin pustules, abscess or omphalitis in addition to signs of sepsis), give IV cloxacillin and gentamicin.\\n* The most serious bacterial infections in newborns should be treated with antibiotics for at least 7â€“10 days.\\n* If an infant is not improving within 2â€“3 days, change the antibiotic treatment or refer the infant for further management.\\n\\n**Other treatment**\\n* If the infant is drowsy or unconscious, ensure that hypoglycaemia is not present (see p. 53); if it is, give 2 ml/kg 10% glucose IV.\\n* Treat convulsions with phenobarbital (see p. 53).\\n* For management of pus draining from eyes, see p. 66.\\n* If the child is from a malarious area and has fever, take a blood film to check for malaria. Neonatal malaria is very rare. If confirmed, treat with artesunate or quinine (see p. 158).\\n* For supportive care, see p. 56.'}\n",
      "ðŸ“œ Content Preview: MENINGITIS\n",
      "\n",
      "* For newborns with any signs of serious bacterial infection or sepsis, give ampicillin (or penicillin) and gentamicin as first-line antibiotic treatment (for dosages see pp. 69â€“72)\n",
      "* If at greater risk of staphylococcus infection (extensive skin pustules, abscess or omphalitis in additi ...\n",
      "\n",
      "ðŸ”¹ Result #3\n",
      "ðŸ“„ Metadata: {'source': 'POCKET BOOK OF Hospital care', 'page': 78, 'section': '3. YOUNG INFANTS'}\n",
      "ðŸ“œ Content Preview: 3. YOUNG INFANTS\n",
      "\n",
      "3. YOUNG INFANTS\n",
      "\n",
      "# SERIOUS BACTERIAL INFECTION\n",
      "\n",
      "* Treat convulsions with phenobarbital (loading dose 20 mg/kg IV). If convulsions persist, give further doses of phenobarbital 10 mg/kg up to a maximum of 40 mg/kg. Watch for apnoea. Always have a bag-mask available. If needed, conti ...\n",
      "\n",
      "ðŸ”¹ Result #4\n",
      "ðŸ“„ Metadata: {'source': 'POCKET BOOK OF Hospital care', 'page': 106, 'section': '4. COUGH'}\n",
      "ðŸ“œ Content Preview: 4. COUGH\n",
      "\n",
      "4. COUGH\n",
      "\n",
      "# SEVERE PNEUMONIA\n",
      "\n",
      "## Investigations\n",
      "* Measure oxygen saturation with pulse oximetry in all children suspected of having pneumonia.\n",
      "* If possible, obtain a chest X-ray to identify pleural effusion, empyema, pneumothorax, pneumatocoele, interstitial pneumonia or pericardial effus ...\n",
      "\n",
      "ðŸ”¹ Result #5\n",
      "ðŸ“„ Metadata: {'source': 'POCKET BOOK OF Hospital care', 'page': 193, 'section': 'BACTERIAL MENINGITIS\\n\\n**Precaution:** If there are signs of increased intracranial pressure, the potential value of the information from a lumbar puncture should be carefully weighed against the risk of the procedure. If in doubt, it might be better to start treatment for suspected meningitis and delay performing a lumbar puncture (see p. 346).'}\n",
      "ðŸ“œ Content Preview: BACTERIAL MENINGITIS\n",
      "\n",
      "**Precaution:** If there are signs of increased intracranial pressure, the potential value of the information from a lumbar puncture should be carefully weighed against the risk of the procedure. If in doubt, it might be better to start treatment for suspected meningitis and de ...\n",
      "\n",
      "ðŸ”¹ Result #6\n",
      "ðŸ“„ Metadata: {'source': 'POCKET BOOK OF Hospital care', 'page': 124, 'section': '4. COUGH'}\n",
      "ðŸ“œ Content Preview: 4. COUGH\n",
      "\n",
      "4. COUGH\n",
      "\n",
      "# ASTHMA\n",
      "\n",
      "than aminophylline. As it is more widely available, it can be used in children who are not responsive to the medications described above.\n",
      "\n",
      "* Give 50% magnesium sulfate as a bolus of 0.1 ml/kg (50 mg/kg) IV over 20 min.\n",
      "\n",
      "## Aminophylline\n",
      "\n",
      "Aminophylline is not recommended ...\n",
      "\n",
      "ðŸ”¹ Result #7\n",
      "ðŸ“„ Metadata: {'source': 'POCKET BOOK OF Hospital care', 'page': 119, 'section': \"BRONCHIOLITIS\\n\\n**Oxygen**\\n* Give oxygen to all children with severe respiratory distress or oxygen saturation â‰¤ 90% (see section 4.2.1). The recommended method for delivering oxygen is by nasal prongs or a nasal catheter (see p. 312).\\n* The nurse should check, every 3 h, that the prongs are in the correct position and not blocked with mucus, and that all connections are secure.\\n\\n**Antibiotic treatment**\\n* If the infant is treated at home, give amoxicillin (40 mg/kg twice a day) orally for 5 days only if the child has signs of pneumonia (fast breathing and lower chest wall indrawing).\\n* If there are signs of severe pneumonia, give ampicillin at 50 mg/kg or benzylpenicillin at 50 000 U/kg IM or IV every 6 h for at least 5 days and gentamicin 7.5 mg/kg IM or IV once a day for at least 5 days (see p. 82).\\n\\n**Supportive care**\\n* If the child has fever (â‰¥ 39 Â°C or â‰¥ 102.2 Â°F) that appears to be causing distress, give paracetamol.\\n* Ensure that the hospitalized child receives daily maintenance fluids appropriate for age (see section 10.2, p. 304), but avoid overhydration. Encourage breastfeeding and oral fluids.\\n* Encourage the child to eat as soon as food can be taken. Nasogastric feeding should be considered in any patient who is unable to maintain oral intake or hydration (expressed breast milk is the best).\\n* Gentle nasal suction should be used to clear secretions in infants where nasal blockage appears to be causing respiratory distress.\\n\\n**Monitoring**\\nA hospitalized child should be assessed by a nurse every 6 h (or every 3 h if there are signs of very severe illness) and by a doctor at least once a day. Monitor oxygen therapy as described on p. 314. Watch for signs of respiratory failure, i.e. increasing hypoxia and respiratory distress leading to exhaustion.\\n\\n**Complications**\\nIf the child fails to respond to oxygen therapy or the child's condition worsens suddenly, obtain a chest X-ray to look for evidence of pneumothorax.\\nTension pneumothorax associated with severe respiratory distress and shift of the heart requires immediate relief by placing a needle to allow the air that is\\n\\n95\\n\\nCOUGH\\n4.\"}\n",
      "ðŸ“œ Content Preview: BRONCHIOLITIS\n",
      "\n",
      "**Oxygen**\n",
      "* Give oxygen to all children with severe respiratory distress or oxygen saturation â‰¤ 90% (see section 4.2.1). The recommended method for delivering oxygen is by nasal prongs or a nasal catheter (see p. 312).\n",
      "* The nurse should check, every 3 h, that the prongs are in the c ...\n",
      "\n",
      "ðŸ”¹ Result #8\n",
      "ðŸ“„ Metadata: {'source': 'POCKET BOOK OF Hospital care', 'page': 210, 'section': '6. FEVER'}\n",
      "ðŸ“œ Content Preview: 6. FEVER\n",
      "\n",
      "6. FEVER\n",
      "\n",
      "## SEPTIC ARTHRITIS OR OSTEOMYELITIS\n",
      "\n",
      "cephalosporin (see p. 358). Consider complications such as pyelonephritis (tenderness in the costo-vertebral angle and high fever) or septicaemia.\n",
      "\n",
      "â–º Treat young infants aged < 2 months with gentamicin at 7.5 mg/kg IM or IV once daily until t ...\n",
      "\n",
      "ðŸ”¹ Result #9\n",
      "ðŸ“„ Metadata: {'source': 'POCKET BOOK OF Hospital care', 'page': 110, 'section': 'PNEUMONIA'}\n",
      "ðŸ“œ Content Preview: PNEUMONIA\n",
      "\n",
      "PNEUMONIA\n",
      "\n",
      "## Follow-up\n",
      "Children with severe pneumonia may cough for several weeks. As they have been very sick, their nutrition is often poor. Give the vaccinations that are due, and arrange follow-up 2 weeks after discharge, if possible, to check the child's nutrition. Also address risk ...\n",
      "\n",
      "ðŸ”¹ Result #10\n",
      "ðŸ“„ Metadata: {'source': 'POCKET BOOK OF Hospital care', 'page': 231, 'section': 'INFECTION                                                    7. MALNUTRITION'}\n",
      "ðŸ“œ Content Preview: INFECTION                                                    7. MALNUTRITION\n",
      "\n",
      "INFECTION                                                    7. MALNUTRITION\n",
      "\n",
      "## 7.4.5 Infection\n",
      "\n",
      "In severe acute malnutrition, the usual signs of bacterial infection, such as fever, are often absent, yet multiple infectio ...\n"
     ]
    }
   ],
   "source": [
    "# Example user query\n",
    "user_query = \"What are the specific conditions under which a child with pneumonia should not be given intravenous ampicillin and gentamicin?\"\n",
    "\n",
    "# Step 1: Embed the query\n",
    "query_vector = model.encode([user_query], convert_to_numpy=True)\n",
    "\n",
    "# Step 2: Search top-k similar chunks\n",
    "top_k = 10\n",
    "D, I = index.search(query_vector, k=top_k)\n",
    "\n",
    "# Step 3: Get top-k texts and metadata\n",
    "retrieved_texts = [texts[i] for i in I[0]]\n",
    "retrieved_metas = [metadatas[i] for i in I[0]]\n",
    "\n",
    "# Step 4: Display\n",
    "for rank, (text, meta) in enumerate(zip(retrieved_texts, retrieved_metas), 1):\n",
    "    print(f\"\\nðŸ”¹ Result #{rank}\")\n",
    "    print(\"ðŸ“„ Metadata:\", meta)\n",
    "    print(\"ðŸ“œ Content Preview:\", text[:300], \"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "b539e2fe-d2c3-44b9-be91-3bc21d43f9c0",
    "_uuid": "e94d2b0d-2017-4441-99cb-58f0ef62170c",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-06T17:22:54.555223Z",
     "iopub.status.busy": "2025-08-06T17:22:54.554806Z",
     "iopub.status.idle": "2025-08-06T17:22:57.682254Z",
     "shell.execute_reply": "2025-08-06T17:22:57.681605Z",
     "shell.execute_reply.started": "2025-08-06T17:22:54.555200Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "!pip install -q google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "20f69884-6c1f-42b1-bcf9-260d3bf427ea",
    "_uuid": "c80872b3-8944-4459-8691-fe95d0b24b5a",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-06T17:22:57.683559Z",
     "iopub.status.busy": "2025-08-06T17:22:57.683276Z",
     "iopub.status.idle": "2025-08-06T17:22:58.554025Z",
     "shell.execute_reply": "2025-08-06T17:22:58.553199Z",
     "shell.execute_reply.started": "2025-08-06T17:22:57.683535Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import google.generativeai as genai\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \" \"\n",
    "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "2a2cd9a0-c3f8-46d2-8fd5-291e9c5553ef",
    "_uuid": "1d6a2e90-370f-4cab-a154-f43a2fafd1bc",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-05T23:00:46.716430Z",
     "iopub.status.busy": "2025-08-05T23:00:46.716137Z",
     "iopub.status.idle": "2025-08-05T23:00:46.722490Z",
     "shell.execute_reply": "2025-08-05T23:00:46.721689Z",
     "shell.execute_reply.started": "2025-08-05T23:00:46.716400Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Format LLM prompt\n",
    "context_blocks = []\n",
    "for i in range(len(retrieved_texts)):\n",
    "    context_blocks.append(\n",
    "        f\"---\\nSource: {retrieved_metas[i]['source']}, Page: {retrieved_metas[i]['page']}\\n{retrieved_texts[i].strip()}\"\n",
    "    )\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are a helpful clinical assistant. Use only the provided context to answer.\\n\"\n",
    "    \"Always properly cite the source and page number from the metadata adn the provided context. The response should be easly readable by a person.\"\n",
    ")\n",
    "\n",
    "final_prompt = f\"{system_prompt}\\n\\nUser Query:\\n{user_query}\\n\\nContext:\\n\" + \"\\n\\n\".join(context_blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "a1e1210b-99c6-463a-87fe-f1e285c6f93e",
    "_uuid": "73cf9300-922e-4bbb-948b-32e901a228b0",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-05T23:35:42.693625Z",
     "iopub.status.busy": "2025-08-05T23:35:42.693069Z",
     "iopub.status.idle": "2025-08-05T23:35:54.440247Z",
     "shell.execute_reply": "2025-08-05T23:35:54.439493Z",
     "shell.execute_reply.started": "2025-08-05T23:35:42.693602Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¤– Gemini Answer:\n",
      "\n",
      "A child with pneumonia should not be given intravenous ampicillin and gentamicin under the following specific conditions:\n",
      "\n",
      "1.  **Suspected Staphylococcal Pneumonia with No Improvement after 48 Hours:** If a child with pneumonia does not show signs of improvement within 48 hours and staphylococcal pneumonia is suspected, treatment should switch to cloxacillin and gentamicin. Signs suggesting staphylococcal pneumonia include rapid clinical deterioration despite treatment, a pneumatocoele or pneumothorax with effusion on chest X-ray, numerous Gram-positive cocci in a sputum smear, heavy growth of *S. aureus* in cultured sputum or empyema fluid, or the presence of septic skin pustules.\n",
      "    *   Source: POCKET BOOK OF Hospital care, Page: 106, 107\n",
      "\n",
      "2.  **Failure of First-Line Treatment:** In cases where the initial first-line treatment (intravenous ampicillin and gentamicin) fails, ceftriaxone should be used as an alternative.\n",
      "    *   Source: POCKET BOOK OF Hospital care, Page: 106\n",
      "\n",
      "3.  **Non-Severe Pneumonia Treated as Outpatient:** For children diagnosed with pneumonia who are treated as outpatients (implying it is not severe pneumonia requiring hospitalization), oral amoxicillin is the recommended antibiotic therapy instead of intravenous ampicillin and gentamicin.\n",
      "    *   Source: POCKET BOOK OF Hospital care, Page: 110\n"
     ]
    }
   ],
   "source": [
    "model_ai = genai.GenerativeModel(\"gemini-2.5-flash\")\n",
    "\n",
    "response = model_ai.generate_content(final_prompt)\n",
    "\n",
    "print(\"ðŸ¤– Gemini Answer:\\n\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_cell_guid": "149d76e7-65cd-44ce-8e14-5b36f2a0d157",
    "_uuid": "35ea7a2a-cb9b-4f53-8a98-8865129ac77e",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-08-06T17:22:58.555198Z",
     "iopub.status.busy": "2025-08-06T17:22:58.554924Z",
     "iopub.status.idle": "2025-08-06T17:22:58.566128Z",
     "shell.execute_reply": "2025-08-06T17:22:58.565414Z",
     "shell.execute_reply.started": "2025-08-06T17:22:58.555174Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# rag_incremental_indexer.py\n",
    "\n",
    "import json\n",
    "import pickle\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import google.generativeai as genai\n",
    "\n",
    "class RAGIndexer:\n",
    "    def __init__(self, \n",
    "                 faiss_index_path=\"faiss_index.index\", \n",
    "                 texts_path=\"texts.pkl\", \n",
    "                 metadatas_path=\"metadatas.pkl\", \n",
    "                 embedding_model_name=\"NeuML/pubmedbert-base-embeddings\",\n",
    "                 gemini_model_name=\"gemini-2.5-flash\"):\n",
    "\n",
    "        self.faiss_index_path = faiss_index_path\n",
    "        self.texts_path = texts_path\n",
    "        self.metadatas_path = metadatas_path\n",
    "        self.gemini_model_name = gemini_model_name\n",
    "\n",
    "        # Load embedding model\n",
    "        self.model = SentenceTransformer(embedding_model_name)\n",
    "\n",
    "        # Try to load existing index and data\n",
    "        try:\n",
    "            self.index = faiss.read_index(self.faiss_index_path)\n",
    "            with open(self.texts_path, \"rb\") as f:\n",
    "                self.texts = pickle.load(f)\n",
    "            with open(self.metadatas_path, \"rb\") as f:\n",
    "                self.metadatas = pickle.load(f)\n",
    "            length = len(self.metadatas)\n",
    "            print(f\"âœ… Loaded existing index and data {len(self.metadatas)}\")\n",
    "        except:\n",
    "            self.index = None\n",
    "            self.texts = []\n",
    "            self.metadatas = []\n",
    "            print(\"âš ï¸ Starting with empty index.\")\n",
    "\n",
    "    def update_with_jsonl(self, jsonl_path):\n",
    "        # Load new JSONL file\n",
    "        new_texts = []\n",
    "        new_metas = []\n",
    "        with open(jsonl_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            for line in f:\n",
    "                obj = json.loads(line)\n",
    "                new_texts.append(obj[\"content\"])\n",
    "                new_metas.append(obj[\"metadata\"])\n",
    "\n",
    "        # Embed new content\n",
    "        new_embeddings = self.model.encode(new_texts, convert_to_numpy=True)\n",
    "\n",
    "        # Initialize index if needed\n",
    "        if self.index is None:\n",
    "            dim = new_embeddings.shape[1]\n",
    "            self.index = faiss.IndexFlatL2(dim)\n",
    "\n",
    "        # Add to index and local lists\n",
    "        self.index.add(new_embeddings)\n",
    "        self.texts.extend(new_texts)\n",
    "        self.metadatas.extend(new_metas)\n",
    "\n",
    "        # Save everything back\n",
    "        faiss.write_index(self.index, self.faiss_index_path)\n",
    "        with open(self.texts_path, \"wb\") as f:\n",
    "            pickle.dump(self.texts, f)\n",
    "        with open(self.metadatas_path, \"wb\") as f:\n",
    "            pickle.dump(self.metadatas, f)\n",
    "\n",
    "        print(f\"âœ… Added {len(new_texts)} chunks from {jsonl_path}\")\n",
    "\n",
    "    def search(self, query, top_k=10):\n",
    "        # Encode query\n",
    "        query_vec = self.model.encode([query], convert_to_numpy=True)\n",
    "\n",
    "        # Search\n",
    "        D, I = self.index.search(query_vec, top_k)\n",
    "\n",
    "        return [(self.texts[i], self.metadatas[i], D[0][rank]) for rank, i in enumerate(I[0])]\n",
    "\n",
    "    def generate_answer(self, query, top_k=3, api_key=None):\n",
    "        if api_key:\n",
    "            genai.configure(api_key=api_key)\n",
    "\n",
    "        model = genai.GenerativeModel(self.gemini_model_name)\n",
    "        results = self.search(query, top_k=top_k)\n",
    "\n",
    "        context_blocks = []\n",
    "        for text, meta, score in results:\n",
    "            context_blocks.append(\n",
    "                f\"Page: {meta['page']}, Section: {meta.get('section', '')}\\n{text.strip()}\"\n",
    "            )\n",
    "\n",
    "        system_prompt = (\n",
    "            \"You are a helpful clinical assistant. Use only the provided context to answer.\\n\"\n",
    "            \"Always cite the source and page number from the metadata.\"\n",
    "        )\n",
    "\n",
    "        final_prompt = f\"{system_prompt}\\n\\nUser Query:\\n{query}\\n\\nContext:\\n\" + \"\\n\\n\".join(context_blocks)\n",
    "\n",
    "        response = model.generate_content(final_prompt)\n",
    "        return response.text\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# indexer = RAGIndexer()\n",
    "# indexer.update_with_jsonl(\"value_plus_md_chunks_NEW.jsonl\")\n",
    "# answer = indexer.generate_answer(\"What is the dosage of ampicillin for a neonate?\", api_key=\"your-gemini-api-key\")\n",
    "# print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T17:22:58.567105Z",
     "iopub.status.busy": "2025-08-06T17:22:58.566833Z",
     "iopub.status.idle": "2025-08-06T17:23:14.372393Z",
     "shell.execute_reply": "2025-08-06T17:23:14.371758Z",
     "shell.execute_reply.started": "2025-08-06T17:22:58.567079Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded existing index and data 438\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b4ee6642ddb45d7a50279babaa62b8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Added 80 chunks from /kaggle/input/chunks/page_chunks_Integrated_management.jsonl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfbbc4b19ef046feabb6b31b5393717a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context:\n",
      "\n",
      "**1. Correct classification for this child's condition:**\n",
      "The child is 10 months old.\n",
      "*   Breathing rate is 55 breaths per minute, which is considered fast breathing for a child aged 2â€“11 months (â‰¥ 50 breaths per minute). (Page 76, 6)\n",
      "*   The child has chest indrawing. (Page 6)\n",
      "*   The context states that \"Chest indrawing or Fast breathing\" classifies as **PNEUMONIA**. (Page 6)\n",
      "Although the child is lethargic, the provided context does not explicitly define \"lethargy\" as a \"general danger sign\" to classify the condition as \"SEVERE PNEUMONIA OR VERY SEVERE DISEASE\". Therefore, based strictly on the explicit criteria in the provided tables, the classification is PNEUMONIA.\n",
      "\n",
      "**2. Immediate course of treatment:**\n",
      "For a child classified with PNEUMONIA:\n",
      "*   Give oral Amoxicillin for 5 days. (Page 6)\n",
      "*   Soothe the throat and relieve the cough with a safe remedy. (Page 6)\n",
      "*   Advise the mother when to return immediately. (Page 6)\n",
      "\n",
      "**3. Required follow-up visit schedule:**\n",
      "*   Follow-up in 3 days. (Page 6)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "indexer = RAGIndexer()\n",
    "answer = indexer.update_with_jsonl(\"/kaggle/input/chunks/page_chunks_Integrated_management.jsonl\")\n",
    "chat = indexer.generate_answer(\n",
    "    query = \"A 10-month-old infant is brought to the clinic with a cough that has lasted for 5 days. The breathing rate is 55 breaths per minute, and the child is observed to have chest indrawing, but no stridor. The child's mother states that the child is also lethargic. What is the correct classification for this child's condition, the immediate course of treatment, and what is the required follow-up visit schedule?\",\n",
    "    top_k = 5,\n",
    "    api_key = \" \"  # Replace with your actual API key\n",
    ")\n",
    "\n",
    "print(chat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T18:10:35.324150Z",
     "iopub.status.busy": "2025-08-06T18:10:35.323865Z",
     "iopub.status.idle": "2025-08-06T18:10:35.327968Z",
     "shell.execute_reply": "2025-08-06T18:10:35.327339Z",
     "shell.execute_reply.started": "2025-08-06T18:10:35.324130Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from google.generativeai import GenerativeModel\n",
    "\n",
    "chat_memory = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T18:10:35.770481Z",
     "iopub.status.busy": "2025-08-06T18:10:35.770238Z",
     "iopub.status.idle": "2025-08-06T18:10:35.774300Z",
     "shell.execute_reply": "2025-08-06T18:10:35.773549Z",
     "shell.execute_reply.started": "2025-08-06T18:10:35.770463Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T18:10:36.481544Z",
     "iopub.status.busy": "2025-08-06T18:10:36.480802Z",
     "iopub.status.idle": "2025-08-06T18:10:36.485351Z",
     "shell.execute_reply": "2025-08-06T18:10:36.484710Z",
     "shell.execute_reply.started": "2025-08-06T18:10:36.481521Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def is_follow_up(query, last_query, api_key):\n",
    "    prompt = f\"\"\"\n",
    "Determine if the second question is a follow-up to the first.\n",
    "\n",
    "Q1: \"{last_query}\"\n",
    "Q2: \"{query}\"\n",
    "\n",
    "Respond only with YES or NO.\n",
    "\"\"\"\n",
    "    checker = GenerativeModel(\"gemini-2.5-flash\")\n",
    "    response = checker.generate_content(prompt)\n",
    "    return \"yes\" in response.text.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T18:10:39.021474Z",
     "iopub.status.busy": "2025-08-06T18:10:39.021193Z",
     "iopub.status.idle": "2025-08-06T18:10:39.026035Z",
     "shell.execute_reply": "2025-08-06T18:10:39.025024Z",
     "shell.execute_reply.started": "2025-08-06T18:10:39.021454Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def reformulate_query(query, last_query, api_key):\n",
    "    prompt = f\"\"\"\n",
    "Rephrase the second question so that it becomes a standalone version using context from the first.\n",
    "\n",
    "Q1: \"{last_query}\"\n",
    "Q2: \"{query}\"\n",
    "\n",
    "Standalone version:\n",
    "\"\"\"\n",
    "    model = GenerativeModel(\"gemini-2.5-flash\")\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text.strip().strip('\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T18:10:39.575521Z",
     "iopub.status.busy": "2025-08-06T18:10:39.574801Z",
     "iopub.status.idle": "2025-08-06T18:10:39.580052Z",
     "shell.execute_reply": "2025-08-06T18:10:39.579292Z",
     "shell.execute_reply.started": "2025-08-06T18:10:39.575490Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def retrieve_chunks(query, indexer, top_k=5):\n",
    "    embedding = indexer.model.encode([query])[0]\n",
    "    _, I = indexer.index.search(np.array([embedding]), top_k)\n",
    "    chunks = [indexer.texts[i] for i in I[0]]\n",
    "    metadatas = [indexer.metadatas[i] for i in I[0]]\n",
    "\n",
    "    # print(\"\\nðŸ” Retrieved Chunks:\")\n",
    "    # for idx, (chunk, meta) in enumerate(zip(chunks, metadatas), 1):\n",
    "    #     print(f\"\\n--- Chunk #{idx} ---\")\n",
    "    #     print(f\"ðŸ“„ Source: {meta.get('source')} | Page: {meta.get('page')} | Section: {meta.get('section', 'N/A')}\")\n",
    "    #     print(f\"ðŸ“š Content:\\n{chunk[:500]}...\")  # trim long text\n",
    "    return chunks, metadatas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T18:10:42.408822Z",
     "iopub.status.busy": "2025-08-06T18:10:42.408584Z",
     "iopub.status.idle": "2025-08-06T18:10:42.413219Z",
     "shell.execute_reply": "2025-08-06T18:10:42.412525Z",
     "shell.execute_reply.started": "2025-08-06T18:10:42.408805Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def generate_response(query, chunks, history, api_key):\n",
    "    history_text = \"\"\n",
    "    for turn in history[-5:]:\n",
    "        history_text += f\"User: {turn['query']}\\nAssistant: {turn['answer']}\\n\"\n",
    "\n",
    "    context_text = \"\\n\\n\".join(chunks)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "You are a helpful medical assistant. Use only the provided context below and the chat history (if any) to answer the current question.\n",
    "Also you have to provide the source and the accurate page from the context that you are using to answer.\n",
    "\n",
    "{history_text}\n",
    "Context:\n",
    "{context_text}\n",
    "\n",
    "User: {query}\n",
    "Assistant:\"\"\"\n",
    "\n",
    "    model = GenerativeModel(\"gemini-2.5-flash\")\n",
    "    response = model.generate_content(prompt)\n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T18:12:41.842918Z",
     "iopub.status.busy": "2025-08-06T18:12:41.842251Z",
     "iopub.status.idle": "2025-08-06T18:12:41.846481Z",
     "shell.execute_reply": "2025-08-06T18:12:41.845720Z",
     "shell.execute_reply.started": "2025-08-06T18:12:41.842895Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def log_turn(session_id, query, answer):\n",
    "    chat_memory[session_id].append({\"query\": query, \"answer\": answer})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T18:14:10.306138Z",
     "iopub.status.busy": "2025-08-06T18:14:10.305877Z",
     "iopub.status.idle": "2025-08-06T18:14:10.311220Z",
     "shell.execute_reply": "2025-08-06T18:14:10.310538Z",
     "shell.execute_reply.started": "2025-08-06T18:14:10.306120Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def conversational_rag_pipeline(query, session_id, indexer, api_key):\n",
    "    history = chat_memory[session_id]\n",
    "    \n",
    "    # Step 1: Handle follow-up logic\n",
    "    if history:\n",
    "        last_query = history[-1][\"query\"]\n",
    "        print(last_query)\n",
    "        if is_follow_up(query, last_query, api_key):\n",
    "            print(\"yes\")\n",
    "            chat_memory[session_id] = []\n",
    "            rewritten_query = reformulate_query(query, last_query, api_key)\n",
    "        else:\n",
    "            rewritten_query = query\n",
    "            history = []  # discard history for unrelated question\n",
    "    else:\n",
    "        rewritten_query = query\n",
    "\n",
    "    # Step 2: Retrieve and generate\n",
    "    chunks, metas = retrieve_chunks(rewritten_query, indexer)\n",
    "    answer = generate_response(query, chunks, history, api_key)\n",
    "\n",
    "    # Step 3: Store the turn\n",
    "    log_turn(session_id, query, answer)\n",
    "    \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T18:14:11.941784Z",
     "iopub.status.busy": "2025-08-06T18:14:11.941111Z",
     "iopub.status.idle": "2025-08-06T18:14:11.945284Z",
     "shell.execute_reply": "2025-08-06T18:14:11.944689Z",
     "shell.execute_reply.started": "2025-08-06T18:14:11.941754Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "chat_memory[\"demo\"] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T18:14:12.518029Z",
     "iopub.status.busy": "2025-08-06T18:14:12.517321Z",
     "iopub.status.idle": "2025-08-06T18:14:24.697384Z",
     "shell.execute_reply": "2025-08-06T18:14:24.696591Z",
     "shell.execute_reply.started": "2025-08-06T18:14:12.518004Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e7e36d5f73840fa9d1ecce4c04eb218",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â“ Q1 Answer:\n",
      " The dosage of ampicillin for young infants (neonates) is 50 mg per kg.\n",
      "\n",
      "Source: TREAT AND COUNSEL, TREAT THE YOUNG INFANT, GIVE FIRST DOSE OF INTRAMUSCULAR ANTIBIOTICS, page 69.\n",
      "What is the dosage of ampicillin for neonates?\n",
      "yes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd1853661b4844ccbd70a3d5234ec8ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â“ Q2 Answer:\n",
      " If the child is severely malnourished and has complications (such as hypoglycaemia, hypothermia, lethargy, or other medical complications), the dosage for ampicillin is 50 mg per kg, given intramuscularly (IM) or intravenously (IV) every 6 hours for 2 days.\n",
      "\n",
      "Source: INFECTION, 7.4.5 Infection, Choice of broad-spectrum antibiotics, page 207.\n"
     ]
    }
   ],
   "source": [
    "# First turn\n",
    "response_1 = conversational_rag_pipeline(\n",
    "    query=\"What is the dosage of ampicillin for neonates?\",\n",
    "    session_id=\"demo\",\n",
    "    indexer=indexer,\n",
    "    api_key=\" \"\n",
    ")\n",
    "print(\"â“ Q1 Answer:\\n\", response_1)\n",
    "\n",
    "# Follow-up turn\n",
    "response_2 = conversational_rag_pipeline(\n",
    "    query=\"And what if the child is also severely malnourished? then what wil be the dosage of ampicillin?\",\n",
    "    session_id=\"demo\",\n",
    "    indexer=indexer,\n",
    "    api_key=\" \"  # Replace with your actual API key\n",
    ")\n",
    "print(\"\\nâ“ Q2 Answer:\\n\", response_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T18:14:42.724195Z",
     "iopub.status.busy": "2025-08-06T18:14:42.723928Z",
     "iopub.status.idle": "2025-08-06T18:14:52.280465Z",
     "shell.execute_reply": "2025-08-06T18:14:52.279638Z",
     "shell.execute_reply.started": "2025-08-06T18:14:42.724175Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "And what if the child is also severely malnourished? then what wil be the dosage of ampicillin?\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daed471c1c3f4ec480ffd19ce9acceb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "â“ Q3 Answer:\n",
      " The steps and process of Neonatal resuscitation are as follows:\n",
      "\n",
      "**Initial Steps:**\n",
      "*   Dry the infant immediately with a clean cloth.\n",
      "*   Keep warm by skin-to-skin contact and covered.\n",
      "\n",
      "**Assessment:**\n",
      "*   Look for: Breathing or crying, good muscle tone or vigorous movements.\n",
      "*   If not present:\n",
      "    *   Stimulate by rubbing the back 2 to 3 times.\n",
      "    *   Suction only if there was meconium-stained liquor and the infant is not crying and moving limbs, or if the mouth or nose is full of secretions with clear amniotic fluid. (Avoid routine suctioning or deep suctioning).\n",
      "\n",
      "**If Not Breathing or Gasping:**\n",
      "*   CALL FOR HELP.\n",
      "*   Transfer to newborn resuscitation area.\n",
      "*   Position the head/neck slightly extended to open the airway.\n",
      "*   Start positive pressure ventilation with a mask and self-inflating bag within 1 minute of birth. (Use air for infants > 32 weeks gestation, or 30% oxygen for very preterm infants if possible).\n",
      "\n",
      "**A. Airway:**\n",
      "*   Keep the infant's head in a slightly extended position.\n",
      "*   Choose a mask size that fits over the nose and mouth (size 1 for normal-weight infant, size 0 for small (< 2.5 kg) infants).\n",
      "\n",
      "**B. Breathing:**\n",
      "*   Ventilate with bag and mask at 40â€“60 breaths/min.\n",
      "*   Make sure the chest moves up with each press on the bag; for very small infants, ensure the chest does not move too much to avoid pneumothorax.\n",
      "*   After 30â€“60 seconds of ventilation with adequate chest movements, check the heart rate (HR) with a stethoscope.\n",
      "    *   If HR 60â€“100/min: Take ventilation corrective steps, continue to ventilate at 40 breaths per min, consider higher oxygen concentration, suction if necessary, reassess every 1â€“2 min.\n",
      "    *   If HR > 100/min: Continue to ventilate at 40 breaths per min, every 1â€“2 min stop to see if breathing spontaneously. Stop ventilating when respiratory rate is > 30 breaths per min. Give post resuscitation care.\n",
      "\n",
      "**C. Circulation:**\n",
      "*   Give chest compressions if the heart rate is < 60/min after 30â€“60 seconds of ventilation with adequate chest movements.\n",
      "*   Compressions should be coordinated with breaths: 90 compressions coordinated with 30 breaths/min (a ratio of three compressions to one breath every 2 seconds).\n",
      "*   Place thumbs just below the line connecting the nipples on the sternum.\n",
      "*   Compress one third the anteriorâ€“posterior diameter of the chest.\n",
      "*   If HR remains at < 60/min, consider other ventilatory support, IV adrenaline, and referral where possible.\n",
      "\n",
      "**Source:**\n",
      "*   Page 47, Chart 12. Neonatal resuscitation: Flow chart\n",
      "*   Page 48, Chart 12. Neonatal resuscitation: Steps and process\n",
      "*   Page 50, 3.2.1 Post resuscitation care\n"
     ]
    }
   ],
   "source": [
    "response_3 = conversational_rag_pipeline(\n",
    "    query=\"what are the steps and process of Neonatal resuscitation\",\n",
    "    session_id=\"demo\",\n",
    "    indexer=indexer,\n",
    "    api_key=\" \"\n",
    ")\n",
    "print(\"\\nâ“ Q3 Answer:\\n\", response_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T18:18:14.064580Z",
     "iopub.status.busy": "2025-08-06T18:18:14.063854Z",
     "iopub.status.idle": "2025-08-06T18:18:25.076108Z",
     "shell.execute_reply": "2025-08-06T18:18:25.075020Z",
     "shell.execute_reply.started": "2025-08-06T18:18:14.064556Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what are the steps and process of Neonatal resuscitation\n",
      "yes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75b3a4beef43458885e9b3e2192a17a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â“ Q1 Answer:\n",
      " It is appropriate to consider discontinuing after effective resuscitation efforts if:\n",
      "*   The infant is not breathing and heartbeat is not detectable beyond 10 minutes.\n",
      "*   If there is no spontaneous breathing and the heart rate remains below 60/min after 20 minutes of effective resuscitation.\n",
      "\n",
      "**Source:** 3.2.2 Cessation of resuscitation, page 50.\n"
     ]
    }
   ],
   "source": [
    "# First turn\n",
    "response_4 = conversational_rag_pipeline(\n",
    "    query=\"when to consider discontinuing after effective resuscitation efforts\",\n",
    "    session_id=\"demo\",\n",
    "    indexer=indexer,\n",
    "    api_key=\" \"\n",
    ")\n",
    "print(\"â“ Q4 Answer:\\n\", response_4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T18:19:51.542514Z",
     "iopub.status.busy": "2025-08-06T18:19:51.542219Z",
     "iopub.status.idle": "2025-08-06T18:20:10.723968Z",
     "shell.execute_reply": "2025-08-06T18:20:10.723116Z",
     "shell.execute_reply.started": "2025-08-06T18:19:51.542490Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# First turn\n",
    "response_4 = conversational_rag_pipeline(\n",
    "    query=\" the air escaping from the mask what to do\",\n",
    "    session_id=\"demo\",\n",
    "    indexer=indexer,\n",
    "    api_key=\" \"\n",
    ")\n",
    "print(\"â“ Q4 Answer:\\n\", response_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T17:24:03.521066Z",
     "iopub.status.busy": "2025-08-06T17:24:03.520787Z",
     "iopub.status.idle": "2025-08-06T17:24:03.524490Z",
     "shell.execute_reply": "2025-08-06T17:24:03.523854Z",
     "shell.execute_reply.started": "2025-08-06T17:24:03.521046Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "chat_log = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T17:24:09.362129Z",
     "iopub.status.busy": "2025-08-06T17:24:09.361863Z",
     "iopub.status.idle": "2025-08-06T17:24:09.366212Z",
     "shell.execute_reply": "2025-08-06T17:24:09.365395Z",
     "shell.execute_reply.started": "2025-08-06T17:24:09.362109Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def log_turn(session_id, query, answer):\n",
    "    chat_log[session_id].append({\n",
    "        \"query\": query,\n",
    "        \"answer\": answer\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T17:24:17.239262Z",
     "iopub.status.busy": "2025-08-06T17:24:17.238714Z",
     "iopub.status.idle": "2025-08-06T17:24:17.242811Z",
     "shell.execute_reply": "2025-08-06T17:24:17.241887Z",
     "shell.execute_reply.started": "2025-08-06T17:24:17.239237Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "active_context = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T17:24:26.933238Z",
     "iopub.status.busy": "2025-08-06T17:24:26.932968Z",
     "iopub.status.idle": "2025-08-06T17:24:26.938019Z",
     "shell.execute_reply": "2025-08-06T17:24:26.937268Z",
     "shell.execute_reply.started": "2025-08-06T17:24:26.933220Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def update_context(session_id, query, api_key):\n",
    "    history = chat_log[session_id]\n",
    "    \n",
    "    if not history:\n",
    "        return [], query\n",
    "\n",
    "    last_query = history[-1][\"query\"]\n",
    "    if is_follow_up(query, last_query, api_key):\n",
    "        rewritten = reformulate_query(query, last_query, api_key)\n",
    "        return active_context[session_id], rewritten\n",
    "    else:\n",
    "        # Not a follow-up â†’ but keep full history safe\n",
    "        active_context[session_id] = []\n",
    "        return [], query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-06T17:24:58.323443Z",
     "iopub.status.busy": "2025-08-06T17:24:58.323096Z",
     "iopub.status.idle": "2025-08-06T17:24:58.328412Z",
     "shell.execute_reply": "2025-08-06T17:24:58.327681Z",
     "shell.execute_reply.started": "2025-08-06T17:24:58.323420Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def conversational_rag_pipeline(query, session_id, indexer, api_key):\n",
    "    context_turns, rewritten_query = update_context(session_id, query, api_key)\n",
    "\n",
    "    # Step 2: Retrieve relevant knowledge\n",
    "    chunks, metas = retrieve_chunks(rewritten_query, indexer)\n",
    "\n",
    "    # Step 3: Generate response using only the context window\n",
    "    answer = generate_response(query, chunks, context_turns, api_key)\n",
    "\n",
    "    # Step 4: Store full history\n",
    "    log_turn(session_id, query, answer)\n",
    "\n",
    "    # Step 5: Update context window if it's a follow-up\n",
    "    if context_turns:\n",
    "        active_context[session_id].append({\"query\": query, \"answer\": answer})\n",
    "\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8015292,
     "sourceId": 12683142,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
